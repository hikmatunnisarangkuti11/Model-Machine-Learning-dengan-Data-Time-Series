{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cSrOAnSKeWGG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc399c8-680d-450f-e1e0-a5367448b86d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in the dataset: 20640\n",
            "Threshold for MAE: 0.485002\n",
            "Epoch 1/50\n",
            "413/413 - 7s - loss: 1.0195 - mae: 1.0195 - val_loss: 0.7560 - val_mae: 0.7560 - 7s/epoch - 16ms/step\n",
            "Epoch 2/50\n",
            "413/413 - 2s - loss: 0.6522 - mae: 0.6522 - val_loss: 0.5735 - val_mae: 0.5735 - 2s/epoch - 4ms/step\n",
            "Epoch 3/50\n",
            "413/413 - 2s - loss: 0.5582 - mae: 0.5582 - val_loss: 0.5571 - val_mae: 0.5571 - 2s/epoch - 4ms/step\n",
            "Epoch 4/50\n",
            "413/413 - 2s - loss: 0.5470 - mae: 0.5470 - val_loss: 0.5484 - val_mae: 0.5484 - 2s/epoch - 4ms/step\n",
            "Epoch 5/50\n",
            "413/413 - 3s - loss: 0.5396 - mae: 0.5396 - val_loss: 0.5395 - val_mae: 0.5395 - 3s/epoch - 6ms/step\n",
            "Epoch 6/50\n",
            "413/413 - 4s - loss: 0.5329 - mae: 0.5329 - val_loss: 0.5344 - val_mae: 0.5344 - 4s/epoch - 10ms/step\n",
            "Epoch 7/50\n",
            "413/413 - 3s - loss: 0.5275 - mae: 0.5275 - val_loss: 0.5316 - val_mae: 0.5316 - 3s/epoch - 8ms/step\n",
            "Epoch 8/50\n",
            "413/413 - 3s - loss: 0.5235 - mae: 0.5235 - val_loss: 0.5262 - val_mae: 0.5262 - 3s/epoch - 8ms/step\n",
            "Epoch 9/50\n",
            "413/413 - 3s - loss: 0.5195 - mae: 0.5195 - val_loss: 0.5267 - val_mae: 0.5267 - 3s/epoch - 6ms/step\n",
            "Epoch 10/50\n",
            "413/413 - 2s - loss: 0.5173 - mae: 0.5173 - val_loss: 0.5215 - val_mae: 0.5215 - 2s/epoch - 6ms/step\n",
            "Epoch 11/50\n",
            "413/413 - 2s - loss: 0.5140 - mae: 0.5140 - val_loss: 0.5269 - val_mae: 0.5269 - 2s/epoch - 6ms/step\n",
            "Epoch 12/50\n",
            "413/413 - 2s - loss: 0.5134 - mae: 0.5134 - val_loss: 0.5202 - val_mae: 0.5202 - 2s/epoch - 4ms/step\n",
            "Epoch 13/50\n",
            "413/413 - 2s - loss: 0.5115 - mae: 0.5115 - val_loss: 0.5172 - val_mae: 0.5172 - 2s/epoch - 4ms/step\n",
            "Epoch 14/50\n",
            "413/413 - 2s - loss: 0.5084 - mae: 0.5084 - val_loss: 0.5193 - val_mae: 0.5193 - 2s/epoch - 4ms/step\n",
            "Epoch 15/50\n",
            "413/413 - 2s - loss: 0.5087 - mae: 0.5087 - val_loss: 0.5146 - val_mae: 0.5146 - 2s/epoch - 4ms/step\n",
            "Epoch 16/50\n",
            "413/413 - 2s - loss: 0.5068 - mae: 0.5068 - val_loss: 0.5137 - val_mae: 0.5137 - 2s/epoch - 4ms/step\n",
            "Epoch 17/50\n",
            "413/413 - 3s - loss: 0.5052 - mae: 0.5052 - val_loss: 0.5127 - val_mae: 0.5127 - 3s/epoch - 6ms/step\n",
            "Epoch 18/50\n",
            "413/413 - 2s - loss: 0.5039 - mae: 0.5039 - val_loss: 0.5125 - val_mae: 0.5125 - 2s/epoch - 5ms/step\n",
            "Epoch 19/50\n",
            "413/413 - 2s - loss: 0.5032 - mae: 0.5032 - val_loss: 0.5103 - val_mae: 0.5103 - 2s/epoch - 4ms/step\n",
            "Epoch 20/50\n",
            "413/413 - 2s - loss: 0.5019 - mae: 0.5019 - val_loss: 0.5148 - val_mae: 0.5148 - 2s/epoch - 4ms/step\n",
            "Epoch 21/50\n",
            "413/413 - 2s - loss: 0.5013 - mae: 0.5013 - val_loss: 0.5082 - val_mae: 0.5082 - 2s/epoch - 4ms/step\n",
            "Epoch 22/50\n",
            "413/413 - 2s - loss: 0.5005 - mae: 0.5005 - val_loss: 0.5075 - val_mae: 0.5075 - 2s/epoch - 4ms/step\n",
            "Epoch 23/50\n",
            "413/413 - 2s - loss: 0.4988 - mae: 0.4988 - val_loss: 0.5068 - val_mae: 0.5068 - 2s/epoch - 4ms/step\n",
            "Epoch 24/50\n",
            "413/413 - 2s - loss: 0.4977 - mae: 0.4977 - val_loss: 0.5072 - val_mae: 0.5072 - 2s/epoch - 6ms/step\n",
            "Epoch 25/50\n",
            "413/413 - 2s - loss: 0.4972 - mae: 0.4972 - val_loss: 0.5071 - val_mae: 0.5071 - 2s/epoch - 5ms/step\n",
            "Epoch 26/50\n",
            "413/413 - 2s - loss: 0.4975 - mae: 0.4975 - val_loss: 0.5063 - val_mae: 0.5063 - 2s/epoch - 4ms/step\n",
            "Epoch 27/50\n",
            "413/413 - 2s - loss: 0.4953 - mae: 0.4953 - val_loss: 0.5051 - val_mae: 0.5051 - 2s/epoch - 4ms/step\n",
            "Epoch 28/50\n",
            "413/413 - 2s - loss: 0.4938 - mae: 0.4938 - val_loss: 0.5030 - val_mae: 0.5030 - 2s/epoch - 4ms/step\n",
            "Epoch 29/50\n",
            "413/413 - 2s - loss: 0.4931 - mae: 0.4931 - val_loss: 0.5018 - val_mae: 0.5018 - 2s/epoch - 4ms/step\n",
            "Epoch 30/50\n",
            "413/413 - 2s - loss: 0.4928 - mae: 0.4928 - val_loss: 0.5026 - val_mae: 0.5026 - 2s/epoch - 4ms/step\n",
            "Epoch 31/50\n",
            "413/413 - 2s - loss: 0.4916 - mae: 0.4916 - val_loss: 0.5004 - val_mae: 0.5004 - 2s/epoch - 6ms/step\n",
            "Epoch 32/50\n",
            "413/413 - 2s - loss: 0.4906 - mae: 0.4906 - val_loss: 0.5113 - val_mae: 0.5113 - 2s/epoch - 5ms/step\n",
            "Epoch 33/50\n",
            "413/413 - 2s - loss: 0.4903 - mae: 0.4903 - val_loss: 0.5026 - val_mae: 0.5026 - 2s/epoch - 4ms/step\n",
            "Epoch 34/50\n",
            "413/413 - 2s - loss: 0.4891 - mae: 0.4891 - val_loss: 0.4997 - val_mae: 0.4997 - 2s/epoch - 4ms/step\n",
            "Epoch 35/50\n",
            "413/413 - 2s - loss: 0.4881 - mae: 0.4881 - val_loss: 0.5001 - val_mae: 0.5001 - 2s/epoch - 4ms/step\n",
            "Epoch 36/50\n",
            "413/413 - 2s - loss: 0.4876 - mae: 0.4876 - val_loss: 0.5088 - val_mae: 0.5088 - 2s/epoch - 4ms/step\n",
            "Epoch 37/50\n",
            "413/413 - 2s - loss: 0.4861 - mae: 0.4861 - val_loss: 0.4960 - val_mae: 0.4960 - 2s/epoch - 4ms/step\n",
            "Epoch 38/50\n",
            "413/413 - 2s - loss: 0.4860 - mae: 0.4860 - val_loss: 0.4943 - val_mae: 0.4943 - 2s/epoch - 5ms/step\n",
            "Epoch 39/50\n",
            "413/413 - 2s - loss: 0.4856 - mae: 0.4856 - val_loss: 0.4950 - val_mae: 0.4950 - 2s/epoch - 5ms/step\n",
            "Epoch 40/50\n",
            "413/413 - 2s - loss: 0.4847 - mae: 0.4847 - val_loss: 0.4961 - val_mae: 0.4961 - 2s/epoch - 4ms/step\n",
            "Epoch 41/50\n",
            "413/413 - 2s - loss: 0.4829 - mae: 0.4829 - val_loss: 0.4924 - val_mae: 0.4924 - 2s/epoch - 4ms/step\n",
            "Epoch 42/50\n",
            "413/413 - 2s - loss: 0.4817 - mae: 0.4817 - val_loss: 0.4905 - val_mae: 0.4905 - 2s/epoch - 4ms/step\n",
            "Epoch 43/50\n",
            "413/413 - 2s - loss: 0.4806 - mae: 0.4806 - val_loss: 0.4973 - val_mae: 0.4973 - 2s/epoch - 4ms/step\n",
            "Epoch 44/50\n",
            "413/413 - 2s - loss: 0.4806 - mae: 0.4806 - val_loss: 0.4904 - val_mae: 0.4904 - 2s/epoch - 4ms/step\n",
            "Epoch 45/50\n",
            "413/413 - 2s - loss: 0.4791 - mae: 0.4791 - val_loss: 0.4892 - val_mae: 0.4892 - 2s/epoch - 5ms/step\n",
            "Epoch 46/50\n",
            "413/413 - 2s - loss: 0.4777 - mae: 0.4777 - val_loss: 0.4873 - val_mae: 0.4873 - 2s/epoch - 6ms/step\n",
            "Epoch 47/50\n",
            "413/413 - 2s - loss: 0.4780 - mae: 0.4780 - val_loss: 0.4861 - val_mae: 0.4861 - 2s/epoch - 4ms/step\n",
            "Epoch 48/50\n",
            "413/413 - 2s - loss: 0.4764 - mae: 0.4764 - val_loss: 0.4853 - val_mae: 0.4853 - 2s/epoch - 4ms/step\n",
            "Epoch 49/50\n",
            "\n",
            "Reached MAE threshold (0.485002). Stopping training.\n",
            "413/413 - 2s - loss: 0.4751 - mae: 0.4751 - val_loss: 0.4842 - val_mae: 0.4842 - 2s/epoch - 4ms/step\n",
            "Mean Absolute Error (MAE) on Test Set: 9.92% of the scale of the data\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanAbsoluteError\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "# Load the California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "data = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
        "data['PRICE'] = housing.target\n",
        "\n",
        "# Display the number of samples in the dataset\n",
        "num_samples = len(data)\n",
        "print(\"Number of samples in the dataset:\", num_samples)\n",
        "\n",
        "# Check if the dataset has at least 1000 samples\n",
        "if num_samples < 1000:\n",
        "    raise ValueError(\"Dataset must have at least 1000 samples.\")\n",
        "\n",
        "# Select features and target variable\n",
        "features = data.drop('PRICE', axis=1)\n",
        "target = data['PRICE']\n",
        "\n",
        "# Use MinMaxScaler to scale the features\n",
        "scaler = MinMaxScaler()\n",
        "features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the data for LSTM (3D input required)\n",
        "x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
        "x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
        "\n",
        "# Calculate the threshold for MAE (10% of the scale of data)\n",
        "scale = np.max(y_train) - np.min(y_train)\n",
        "threshold_mae = 0.1 * scale\n",
        "print(\"Threshold for MAE:\", threshold_mae)\n",
        "\n",
        "# Custom callback to stop training when both MAE and val MAE are below the threshold\n",
        "class ThresholdCallback(Callback):\n",
        "    def __init__(self, threshold):\n",
        "        super(ThresholdCallback, self).__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs.get('mae') < self.threshold and logs.get('val_mae') < self.threshold:\n",
        "            print(f\"\\nReached MAE threshold ({self.threshold}). Stopping training.\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(50, input_shape=(x_train.shape[1], x_train.shape[2])),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model with specified learning rate and loss function\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss=MeanAbsoluteError(), metrics=['mae'])\n",
        "\n",
        "# Train the model with the custom callback\n",
        "history = model.fit(x_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=2, callbacks=[ThresholdCallback(threshold_mae)])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_mae = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE) in percentage of the scale of the data\n",
        "mae_percentage = test_mae / scale * 100\n",
        "\n",
        "print(f'Mean Absolute Error (MAE) on Test Set: {mae_percentage:.2f}% of the scale of the data')\n"
      ]
    }
  ]
}